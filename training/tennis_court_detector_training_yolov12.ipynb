{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFI4yB3-uHFW"
      },
      "source": [
        "# Fine tuning Yolo 12 for keypoint court detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jm41rvPhxRHa",
        "outputId": "04459c05-7111-4144-ea9b-2e8752433368"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkDOC4Z_xyw-",
        "outputId": "1e292feb-d02f-431c-be78-f8aa9f0c96db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/TennisAnalytics/training\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/TennisAnalytics/training')\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YZJphhMuHFb"
      },
      "outputs": [],
      "source": [
        "#!wget --header=\"Host: drive.usercontent.google.com\" --header=\"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36\" --header=\"Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7\" --header=\"Accept-Language: en-US,en;q=0.9,ar;q=0.8\" --header=\"Cookie: HSID=Ag2OIHvsd2Wub4C7z; SSID=AWnBcQKwDHiTrZAU1; APISID=pltrFZgE9lJ0o1gq/AN9feEHYvs8oHd519; SAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; __Secure-1PAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; __Secure-3PAPISID=zgF45F21ZPWzYWZw/AgUMJ8b7QQXuWGn19; SID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-uttBbVDRolhF-hY16nwHXw0gACgYKAWISAQASFQHGX2MivNTw_E_toJuIRy6LMpKNOBoVAUF8yKpFSmvq7AMjvEWeNc50Zff40076; __Secure-1PSID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-utbSY2jBY1VXuw8gYl5hIO2QACgYKAXsSAQASFQHGX2MihVCJ1PwLozGqZgdSatM9QhoVAUF8yKpgrsTvI8i_UE-YHpoN7Gx-0076; __Secure-3PSID=g.a000fwgYx1PcnW-rFyFhg3x6mQHzCrwXz-KFhoOLogUl7YTWI-utwVfPl2imdPimZJ9tdDZGQAACgYKAUESAQASFQHGX2MiEJ49mV4jME2kttDAV5hwWBoVAUF8yKp80mIgju1lu-q4nI7VsFDM0076; NID=511=efI9IZpxtyJ7Dw1MAUXU8FlzS5jXGewY4Er8HliWc3A0RSWdgvNDyKY66ETjgRyTGWPbWODSmiSeYSBab5SPHVwqbJxd6ZeGW2f6BkHi61UKksXPH0CVJRM1hKpMjHPU5qw7tboM2Mi87NrosV8COB-GCLulLLbjOoSAEQewTe8NVZ5Owq8IkwvxFGfJkmUKEMkFWrw9yb5nTDl3wbZEsGFI92iEdNTSxSRovNCIPN2US-SCFdQ0m2BtvwdiWZbgnn7dSQ8yPA145Kk2BA-ATpJNJ6SJHEHLQY-9CPail9D5qgJgxR925EUg5RGCpEu9wS5xbA62KTa19wAvbAq7Dk3TWc-iX4p1s7ESFyDC7yMpFxiFPJjqkWwFi_ZfiK2TW2t0TQ60DFBxqOytQaLyHrkEvD-CQPVj6OCOP22cZY0Cu61HaAQgFO9pXH-kJUlywzVdbirJumN5gswyaQ49b3KdLcG0Jb7brOMTM24T2nGtQ10hJzsnTwX7dBk3ujqQrI_DGuURvPassPUrIZ0; AEC=Ae3NU9MOEGeKAZjP6INpOYbyMraWAWztmx5pJB_1ILu1furiTy1K37k15u0; __Secure-1PSIDTS=sidts-CjEBYfD7Z9twEKTWJ9gU7KG-rLbxJGNRQIoG3wH6JVu6yiCC2fsRrm7tN8L6d5WlILrnEAA; __Secure-3PSIDTS=sidts-CjEBYfD7Z9twEKTWJ9gU7KG-rLbxJGNRQIoG3wH6JVu6yiCC2fsRrm7tN8L6d5WlILrnEAA; 1P_JAR=2024-02-18-08; SIDCC=ABTWhQExCxkfmwCkG1RaEgz8U1ZkPeh3HmLMUdMt8S5cNSsLY5U5rAL6wlvq7dtjRw7zrtAbqsFI; __Secure-1PSIDCC=ABTWhQH0jLeRIS6Tu3LS8DXB5Q3gGDq9LTmlk60FKu795Bf0UbzsOcYWVAE96clq5aAL8i724Q0; __Secure-3PSIDCC=ABTWhQHIFcyv3nZYwp78WXEQal71jCE_ZsGT5lXs8VLr7XDIfFqHcLTIPz4HxzJb9ZnYQ5l2s9eU\" --header=\"Connection: keep-alive\" \"https://drive.usercontent.google.com/download?id=1lhAaeQCmk2y440PmagA0KmIVBIysVMwu&export=download&authuser=0&confirm=t&uuid=3077628e-fc9b-4ef2-8cde-b291040afb30&at=APZUnTU9lSikCSe3NqbxV5MVad5T%3A1708243355040\" -c -O 'tennis_court_det_dataset.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAr0K7NVuHFc"
      },
      "outputs": [],
      "source": [
        "#!unzip tennis_court_det_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EohuxE0r_nUq",
        "outputId": "ed9fd481-0117-4a2c-bb9b-b6df00dd9cad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cartella rinominata: data → data_keypoint_detection\n"
          ]
        }
      ],
      "source": [
        "# Percorso originale e nuovo nome\n",
        "old_name = \"data\"\n",
        "new_name = \"data_keypoint_detection\"\n",
        "\n",
        "# Rinomina la cartella\n",
        "if os.path.exists(old_name):\n",
        "    os.rename(old_name, new_name)\n",
        "    print(f\"Cartella rinominata: {old_name} → {new_name}\")\n",
        "else:\n",
        "    print(f\"Cartella non trovata: {old_name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VspJiZLRuHFc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "def process_annotations(split: str = \"train\", move_images: bool = True):\n",
        "    assert split in [\"train\", \"val\"], \"split must be 'train' or 'val'\"\n",
        "\n",
        "    json_filename = f\"data_{split}.json\"\n",
        "    json_path = os.path.join(\"data_keypoint_detection\", json_filename)\n",
        "\n",
        "    with open(json_path, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    folders_to_create = [\n",
        "        f\"data_keypoint_detection/images/{split}\",\n",
        "        f\"data_keypoint_detection/labels/{split}\"\n",
        "    ]\n",
        "    for folder in folders_to_create:\n",
        "        os.makedirs(folder, exist_ok=True)\n",
        "\n",
        "    source_image_dir = \"data_keypoint_detection/images\"\n",
        "    destination_image_dir = f\"data_keypoint_detection/images/{split}\"\n",
        "    destination_label_dir = f\"data_keypoint_detection/labels/{split}\"\n",
        "\n",
        "    for annotation in data:\n",
        "        image_name = annotation['id']\n",
        "        keypoints = annotation['kps']\n",
        "        filename = f\"{image_name}.png\"\n",
        "        src_path = os.path.join(source_image_dir, filename)\n",
        "        dst_path = os.path.join(destination_image_dir, filename)\n",
        "\n",
        "        if move_images:\n",
        "            if os.path.exists(src_path):\n",
        "                shutil.move(src_path, dst_path)\n",
        "            else:\n",
        "                print(f\"Warning: Image not found: {src_path}\")\n",
        "                continue\n",
        "\n",
        "        image_path = dst_path if move_images else src_path\n",
        "        try:\n",
        "            with Image.open(image_path) as img:\n",
        "                width_pixels, height_pixels = img.size\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Warning: Unable to open image: {image_path}\")\n",
        "            continue\n",
        "\n",
        "        # Normalizza e clippa i keypoints\n",
        "        keypoints_normalized = []\n",
        "        for x, y in keypoints:\n",
        "            x_norm = x / width_pixels\n",
        "            y_norm = y / height_pixels\n",
        "\n",
        "            clipped = False\n",
        "            if x_norm < 0:\n",
        "                x_norm = 0.0\n",
        "                clipped = True\n",
        "            elif x_norm > 1:\n",
        "                x_norm = 1.0\n",
        "                clipped = True\n",
        "\n",
        "            if y_norm < 0:\n",
        "                y_norm = 0.0\n",
        "                clipped = True\n",
        "            elif y_norm > 1:\n",
        "                y_norm = 1.0\n",
        "                clipped = True\n",
        "\n",
        "            v = 1 if clipped else 2\n",
        "            keypoints_normalized.append([x_norm, y_norm, v])\n",
        "\n",
        "        external_indices = [0, 1, 2, 3, 4, 5, 6, 7]\n",
        "        subset = [keypoints_normalized[i] for i in external_indices]\n",
        "        x_coords = [pt[0] for pt in subset]\n",
        "        y_coords = [pt[1] for pt in subset]\n",
        "\n",
        "        min_x, max_x = min(x_coords), max(x_coords)\n",
        "        min_y, max_y = min(y_coords), max(y_coords)\n",
        "\n",
        "        center_x = (min_x + max_x) / 2\n",
        "        center_y = (min_y + max_y) / 2\n",
        "        width_box = max_x - min_x\n",
        "        height_box = max_y - min_y\n",
        "\n",
        "        label_filename = os.path.join(destination_label_dir, f\"{image_name}.txt\")\n",
        "        with open(label_filename, \"w\") as f:\n",
        "            bbox_info = [str(v) for v in [0, center_x, center_y, width_box, height_box]]\n",
        "            flat_keypoints = [str(coord) for pt in keypoints_normalized for coord in pt]\n",
        "            f.write(\" \".join(bbox_info + flat_keypoints) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wGRm0H2zuHFc"
      },
      "outputs": [],
      "source": [
        "# Per processare i dati di training\n",
        "process_annotations(split=\"train\", move_images=True)\n",
        "\n",
        "# Per processare i dati di validazione\n",
        "process_annotations(split=\"val\", move_images=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "BGRsCMj4uHFd",
        "outputId": "ae08d1f9-c887-4d33-8be6-c1c52019bded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spostando 'data_keypoint_detection/images' in 'data_keypoint_detection/data_keypoint_detection/images'...\n",
            "Spostando 'data_keypoint_detection/labels' in 'data_keypoint_detection/data_keypoint_detection/labels'...\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data_keypoint_detection/data_keypoint_detection/labels'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# move images and labels folders to data_keypoin_detection folder (new folder)\n",
        "base_path = 'data_keypoint_detection'\n",
        "destination_root = os.path.join(base_path, \"data_keypoint_detection\")\n",
        "os.makedirs(destination_root, exist_ok=True)\n",
        "\n",
        "src_images = os.path.join(base_path, \"images\")\n",
        "dst_images = os.path.join(destination_root, \"images\")\n",
        "print(f\"Spostando '{src_images}' in '{dst_images}'...\")\n",
        "shutil.move(src_images, dst_images)\n",
        "\n",
        "src_labels = os.path.join(base_path, \"labels\")\n",
        "dst_labels = os.path.join(destination_root, \"labels\")\n",
        "print(f\"Spostando '{src_labels}' in '{dst_labels}'...\")\n",
        "shutil.move(src_labels, dst_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1gDvk5LuHFd",
        "outputId": "079e39ff-1853-4d47-faa9-6af90535cc41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLO YAML file scritto in: data_keypoint_detection/data.yaml\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "\n",
        "def write_yolo_yaml(file_path=\"data_keypoint_detection/data.yaml\"):\n",
        "    data = {\n",
        "        \"path\": \"data_keypoint_detection\",\n",
        "        \"names\": [\"court\"],\n",
        "        \"train\": \"data_keypoint_detection/images/train\",\n",
        "        \"val\": \"data_keypoint_detection/images/val\",\n",
        "        \"kpt_shape\": [14,3],\n",
        "        \"flip_idx\": [1, 0, 3, 2, 6, 7, 4, 5, 9, 8, 11, 10, 12, 13]\n",
        "    }\n",
        "\n",
        "    with open(file_path, \"w\") as f:\n",
        "        yaml.dump(data, f, default_flow_style=False, sort_keys=False)\n",
        "    print(f\"YOLO YAML file scritto in: {file_path}\")\n",
        "\n",
        "# Esempio d'uso\n",
        "write_yolo_yaml()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYdH-AJ_uHFe",
        "outputId": "db9795b2-89a8-4c19-bb1c-575bfec3f2ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.168-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.168-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.168 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UdoN_2pzuHFe"
      },
      "outputs": [],
      "source": [
        "#yolo pose train data=data_keypoint_detection/data.yaml model=yolo11n-pose.yaml epochs=100 imgsz=1280"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aAcVYJ-uHFf",
        "outputId": "b96ef7f6-4c95-4171-b74e-15aa5c79056a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Ultralytics 8.3.168 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=True, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data_keypoint_detection/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=4, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1280, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n-pose.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=results_pose, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=results_pose/train, save_frames=False, save_json=False, save_period=1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=pose, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "100% 755k/755k [00:00<00:00, 39.0MB/s]\n",
            "Overriding model.yaml kpt_shape=[17, 3] with kpt_shape=[14, 3]\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
            "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
            "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
            " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
            " 23        [16, 19, 22]  1    653761  ultralytics.nn.modules.head.Pose             [1, [14, 3], [64, 128, 256]]  \n",
            "YOLO11n-pose summary: 196 layers, 2,812,929 parameters, 2,812,913 gradients, 7.3 GFLOPs\n",
            "\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.8±0.4 ms, read: 1.4±0.3 MB/s, size: 795.1 KB)\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/TennisAnalytics/training/data_keypoint_detection/data_keypoint_detection/labels/train... 6630 images, 0 backgrounds, 0 corrupt: 100% 6630/6630 [1:01:05<00:00,  1.81it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/TennisAnalytics/training/data_keypoint_detection/data_keypoint_detection/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.5±0.1 ms, read: 1.7±0.3 MB/s, size: 841.9 KB)\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/TennisAnalytics/training/data_keypoint_detection/data_keypoint_detection/labels/val... 2211 images, 0 backgrounds, 0 corrupt: 100% 2211/2211 [20:33<00:00,  1.79it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/TennisAnalytics/training/data_keypoint_detection/data_keypoint_detection/labels/val.cache\n",
            "Plotting labels to results_pose/train/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 87 weight(decay=0.0), 97 weight(decay=0.0005), 96 bias(decay=0.0)\n",
            "Image sizes 1280 train, 1280 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mresults_pose/train\u001b[0m\n",
            "Starting training for 4 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        1/4      10.2G      2.026      6.527     0.5201      3.114      2.859         19       1280: 100% 415/415 [08:56<00:00,  1.29s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 70/70 [01:16<00:00,  1.10s/it]\n",
            "                   all       2211       2211      0.973      0.976      0.987      0.763      0.975      0.978      0.981      0.422\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        2/4      9.29G     0.8334      1.672     0.3311     0.7676      1.483         17       1280: 100% 415/415 [08:58<00:00,  1.30s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 70/70 [01:17<00:00,  1.10s/it]\n",
            "                   all       2211       2211      0.994      0.994      0.994      0.912      0.993      0.992      0.994      0.905\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        3/4      9.29G     0.5848     0.9383     0.2659     0.4678      1.199         15       1280: 100% 415/415 [09:03<00:00,  1.31s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 70/70 [01:17<00:00,  1.10s/it]\n",
            "                   all       2211       2211      0.996      0.996      0.994      0.911      0.994      0.992      0.994       0.93\n",
            "\n",
            "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n",
            "        4/4      9.29G     0.4659     0.6348     0.2313      0.375      1.088         13       1280: 100% 415/415 [09:05<00:00,  1.32s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 70/70 [01:17<00:00,  1.11s/it]\n",
            "                   all       2211       2211      0.995      0.998      0.994      0.929      0.995      0.992      0.994       0.99\n",
            "\n",
            "4 epochs completed in 0.691 hours.\n",
            "Optimizer stripped from results_pose/train/weights/last.pt, 6.0MB\n",
            "Optimizer stripped from results_pose/train/weights/best.pt, 6.0MB\n",
            "\n",
            "Validating results_pose/train/weights/best.pt...\n",
            "Ultralytics 8.3.168 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLO11n-pose summary (fused): 109 layers, 2,804,989 parameters, 0 gradients, 7.2 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   0% 0/70 [00:00<?, ?it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   1% 1/70 [00:00<00:46,  1.50it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   3% 2/70 [00:01<00:59,  1.15it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   4% 3/70 [00:03<01:25,  1.27s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   6% 4/70 [00:06<02:21,  2.14s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   7% 5/70 [00:09<02:37,  2.42s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):   9% 6/70 [00:12<02:48,  2.64s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  10% 7/70 [00:14<02:19,  2.22s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  11% 8/70 [00:14<01:47,  1.74s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  13% 9/70 [00:16<01:38,  1.61s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  14% 10/70 [00:16<01:14,  1.24s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  16% 11/70 [00:17<01:14,  1.26s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  17% 12/70 [00:19<01:13,  1.27s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  19% 13/70 [00:21<01:21,  1.44s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  20% 14/70 [00:21<01:06,  1.19s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  21% 15/70 [00:23<01:07,  1.23s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  23% 16/70 [00:23<00:52,  1.03it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  24% 17/70 [00:24<00:59,  1.11s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  26% 18/70 [00:25<00:46,  1.11it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  27% 19/70 [00:26<00:55,  1.08s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  29% 20/70 [00:27<00:44,  1.13it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  30% 21/70 [00:28<00:52,  1.08s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  31% 22/70 [00:29<00:41,  1.14it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  33% 23/70 [00:30<00:44,  1.06it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  34% 24/70 [00:30<00:36,  1.27it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  36% 25/70 [00:32<00:53,  1.18s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  37% 26/70 [00:33<00:43,  1.01it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  39% 27/70 [00:35<00:56,  1.31s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  40% 28/70 [00:35<00:43,  1.03s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  41% 29/70 [00:37<00:46,  1.13s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  43% 30/70 [00:37<00:36,  1.10it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  44% 31/70 [00:38<00:42,  1.09s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  46% 32/70 [00:39<00:33,  1.14it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  47% 33/70 [00:40<00:38,  1.05s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  49% 34/70 [00:41<00:30,  1.16it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  50% 35/70 [00:42<00:37,  1.08s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  51% 36/70 [00:43<00:29,  1.14it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  53% 37/70 [00:44<00:35,  1.08s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  54% 38/70 [00:45<00:30,  1.06it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  56% 39/70 [00:47<00:40,  1.29s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  57% 40/70 [00:48<00:32,  1.09s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  59% 41/70 [00:50<00:42,  1.45s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  60% 42/70 [00:50<00:32,  1.16s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  61% 43/70 [00:52<00:34,  1.26s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  63% 44/70 [00:52<00:26,  1.02s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  64% 45/70 [00:54<00:30,  1.21s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  66% 46/70 [00:54<00:23,  1.04it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  67% 47/70 [00:56<00:26,  1.17s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  69% 48/70 [00:56<00:20,  1.06it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  70% 49/70 [00:58<00:23,  1.12s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  71% 50/70 [00:59<00:19,  1.00it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  73% 51/70 [01:01<00:24,  1.30s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  74% 52/70 [01:02<00:21,  1.17s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  76% 53/70 [01:04<00:25,  1.48s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  77% 54/70 [01:04<00:18,  1.15s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  79% 55/70 [01:06<00:18,  1.23s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  80% 56/70 [01:06<00:14,  1.00s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  81% 57/70 [01:07<00:14,  1.12s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  83% 58/70 [01:08<00:11,  1.08it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  84% 59/70 [01:10<00:12,  1.15s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  86% 60/70 [01:10<00:09,  1.08it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  87% 61/70 [01:12<00:10,  1.17s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  89% 62/70 [01:12<00:07,  1.06it/s]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  90% 63/70 [01:14<00:09,  1.32s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  91% 64/70 [01:15<00:06,  1.11s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  93% 65/70 [01:17<00:07,  1.43s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  94% 66/70 [01:18<00:04,  1.17s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  96% 67/70 [01:19<00:03,  1.30s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  97% 68/70 [01:20<00:02,  1.04s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95):  99% 69/70 [01:21<00:01,  1.08s/it]WARNING ⚠️ Model does not support 'augment=True', reverting to single-scale prediction.\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100% 70/70 [01:21<00:00,  1.17s/it]\n",
            "                   all       2211       2211      0.995      0.998      0.994      0.928      0.995      0.992      0.994       0.99\n",
            "Speed: 0.5ms preprocess, 5.9ms inference, 0.0ms loss, 3.1ms postprocess per image\n",
            "Results saved to \u001b[1mresults_pose/train\u001b[0m\n",
            "💡 Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ],
      "source": [
        "# aggiunto early stopping\n",
        "!yolo pose train \\\n",
        "  data=data_keypoint_detection/data.yaml \\\n",
        "  model=yolo11n-pose.yaml \\\n",
        "  epochs=4 \\\n",
        "  imgsz=1280 \\\n",
        "  patience=10 \\\n",
        "  save=True \\\n",
        "  save_period=1 \\\n",
        "  project=results_pose \\\n",
        "  augment = True\n",
        "\n",
        "\n",
        "  # nel futuro da migliorare la normalizzazione: come tratto i keypoints fuori dall'immagine?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laa3smPd7XEH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.20"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}